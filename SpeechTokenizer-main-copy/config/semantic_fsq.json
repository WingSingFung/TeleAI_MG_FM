{
    "training_stage": 0,
    "lm_name": "./checkpoints/tinyllama-chat",
    "stft_cfg": {
        "sampling_rate": 32000,
        "filter_length": 2048,
        "hop_length": 640,
        "win_length": 2048,
        "n_mel_channels": 128,
        "mel_fmin": 0,
        "mel_fmax": 16000
    },
    "vae_cfg": {
        "embed_dim": 64,
        "ddconfig": {
            "double_z": true,
            "in_channels": 128,
            "out_ch": 128,
            "z_channels": 64,
            "kernel_size": 5,
            "ch": 384,
            "ch_mult": [
                1,
                2,
                4
            ],
            "num_res_blocks": 4,
            "attn_layers": [
                3
            ],
            "down_layers": [
                0
            ],
            "dropout": 0.0
        }
    },
    "vocoder_cfg": {
        "upsample_rates": [8,5,2,2,2,2],
        "upsample_kernel_sizes": [16,10,4,4,4,4],
        "upsample_initial_channel": 1536,
        "resblock_kernel_sizes": [3,7,11],
        "resblock_dilation_sizes": [[1,3,5], [1,3,5], [1,3,5]],
        "use_tanh_at_final": false,
        "use_bias_at_final": false,
        "activation": "snakebeta",
        "snake_logscale": true,
        "resblock": "1",
        "num_mels": 128,
        "use_cuda_kernel": true
    },

    "semantic_encoder_cfg":{
        "dim": 1024,
        "mel_dim": 128,
        "depth": 15,
        "heads": 16,
        "dim_head": 64,
        "model_type": "12.5hz",
        "use_conv": false,
        "norm_before_quantize": false
    },

    "ctc_cfg":{
        "in_dim": 1024,
        "num_classes": 32001,
        "blank": 32000
    },

    "vq_type": "fsq",
    "quantizer_cfg": {
        "levels": [4,4,4,4,4,4,4,4],
        "num_quantizers": 1,
        "dim": 1024
    },
    
    "loss_scale_quantizer" : 1.0,


    "stft_config": {
        "sampling_rate": 32000,
        "filter_length": 2048,
        "hop_length": 640,
        "win_length": 2048,
        "n_mel_channels": 128,
        "mel_fmin": 0,
        "mel_fmax": 16000
    },

    "train_files": "/gemini/platform/public/aigc/mh-data/librispeech/LibriSpeech/librispeech_data.json",
    "valid_files": "/gemini/platform/public/aigc/mh-data/librispeech/LibriSpeech/librispeech_data.json",
    "results_folder": "exps_semantic/12_5hz_asr_1008_norm",
    "padding_mode": "zero",
    "sample_rate": 32000,
    "batch_size": 8,
    "epochs":100,
    "learning_rate": 5e-5,
    "initial_learning_rate":1e-6,
    "num_warmup_steps": 10000,
    "betas":[0.9, 0.95],
    "seed": 1234,
    "segment_size": 480000,
    "wd": 1e-2,
    "eps": 1e-6,
    "num_workers": 8,
    "num_ckpt_keep": 3,
    "showpiece_num": 8,
    "accelerator": "gpu",
    "devices": [0,1,2,3,4,5],
    "strategy": "ddp",
    "precision": "bf16-mixed"
}